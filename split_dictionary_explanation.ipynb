{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Luca Riitano 6/10/21**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two algorithms were tried to determine if waveforms were split. The first uses the derivative at block boundaries as a metric. If at least one channel in an ASIC contained a split waveform, we assume the event was split for the entire ASIC. The second uses the peak position of waveforms as a metric. Split waveforms tend to peak very early (~sample 30) or slightly later (sample ~80-90) than clean waveforms. The average peak position of waveforms in all the channels of an ASIC is used to determine the split status. Waveforms that peak at the first or last sample or have peak values of less than 500 ADC are ignored in both algorithms. Note that any missing data will be represented by None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import json to handle json files\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how we load the json file\n",
    "#Load the raw numbers\n",
    "with open('split_dict_raw.json', 'r') as file:\n",
    "    data_raw = json.load(file)\n",
    "#Load the split status\n",
    "with open('split_dict_status.json', 'r') as file:\n",
    "    data_status = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file titled 'split_dict_raw.json' contains the raw number of events that are classified as clean or split by either algorithm. The file contains a multi-level dictionary with keys corresponding to module numbers, ASIC numbers, and run numbers. The value that corresponds to a run number key has an array of dictionaries. Each dictionary in the array corresponds to a subrun. The dictionaries contain the information on the raw event numbers. The example below should make things more clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 subruns in this run: [{'split_split': 0.0, 'split_clean': 0.0, 'clean_split': 0.0, 'clean_clean': 1.0, 'total': 1.0}, {'split_split': 0.0, 'split_clean': 251.0, 'clean_split': 4.0, 'clean_clean': 839.0, 'total': 1094.0}, {'split_split': 0.0, 'split_clean': 263.0, 'clean_split': 6.0, 'clean_clean': 847.0, 'total': 1116.0}, {'split_split': 0.0, 'split_clean': 255.0, 'clean_split': 1.0, 'clean_clean': 841.0, 'total': 1097.0}, {'split_split': 0.0, 'split_clean': 228.0, 'clean_split': 3.0, 'clean_clean': 874.0, 'total': 1105.0}, {'split_split': 0.0, 'split_clean': 264.0, 'clean_split': 3.0, 'clean_clean': 841.0, 'total': 1108.0}, {'split_split': 0.0, 'split_clean': 248.0, 'clean_split': 2.0, 'clean_clean': 858.0, 'total': 1108.0}, {'split_split': 0.0, 'split_clean': 254.0, 'clean_split': 7.0, 'clean_clean': 861.0, 'total': 1122.0}, {'split_split': 2.0, 'split_clean': 276.0, 'clean_split': 1.0, 'clean_clean': 828.0, 'total': 1107.0}, {'split_split': 1.0, 'split_clean': 300.0, 'clean_split': 2.0, 'clean_clean': 808.0, 'total': 1111.0}, {'split_split': 2.0, 'split_clean': 263.0, 'clean_split': 2.0, 'clean_clean': 851.0, 'total': 1118.0}, {'split_split': 1.0, 'split_clean': 226.0, 'clean_split': 5.0, 'clean_clean': 888.0, 'total': 1120.0}, {'split_split': 0.0, 'split_clean': 252.0, 'clean_split': 1.0, 'clean_clean': 858.0, 'total': 1111.0}, {'split_split': 0.0, 'split_clean': 282.0, 'clean_split': 1.0, 'clean_clean': 823.0, 'total': 1106.0}, {'split_split': 1.0, 'split_clean': 255.0, 'clean_split': 1.0, 'clean_clean': 863.0, 'total': 1120.0}, {'split_split': 0.0, 'split_clean': 124.0, 'clean_split': 3.0, 'clean_clean': 389.0, 'total': 516.0}, {'split_split': 0.0, 'split_clean': 0.0, 'clean_split': 0.0, 'clean_clean': 1.0, 'total': 1.0}, {'split_split': 0.0, 'split_clean': 264.0, 'clean_split': 1.0, 'clean_clean': 848.0, 'total': 1113.0}, {'split_split': 0.0, 'split_clean': 258.0, 'clean_split': 0.0, 'clean_clean': 866.0, 'total': 1124.0}, {'split_split': 0.0, 'split_clean': 274.0, 'clean_split': 6.0, 'clean_clean': 837.0, 'total': 1117.0}, {'split_split': 1.0, 'split_clean': 244.0, 'clean_split': 0.0, 'clean_clean': 869.0, 'total': 1114.0}, {'split_split': 2.0, 'split_clean': 263.0, 'clean_split': 3.0, 'clean_clean': 855.0, 'total': 1123.0}, {'split_split': 0.0, 'split_clean': 256.0, 'clean_split': 1.0, 'clean_clean': 862.0, 'total': 1119.0}, {'split_split': 0.0, 'split_clean': 279.0, 'clean_split': 3.0, 'clean_clean': 839.0, 'total': 1121.0}, {'split_split': 0.0, 'split_clean': 270.0, 'clean_split': 1.0, 'clean_clean': 846.0, 'total': 1117.0}, {'split_split': 0.0, 'split_clean': 240.0, 'clean_split': 1.0, 'clean_clean': 870.0, 'total': 1111.0}, {'split_split': 1.0, 'split_clean': 248.0, 'clean_split': 6.0, 'clean_clean': 864.0, 'total': 1119.0}, {'split_split': 0.0, 'split_clean': 258.0, 'clean_split': 1.0, 'clean_clean': 849.0, 'total': 1108.0}, {'split_split': 0.0, 'split_clean': 261.0, 'clean_split': 4.0, 'clean_clean': 849.0, 'total': 1114.0}, {'split_split': 1.0, 'split_clean': 255.0, 'clean_split': 2.0, 'clean_clean': 863.0, 'total': 1121.0}, {'split_split': 0.0, 'split_clean': 263.0, 'clean_split': 2.0, 'clean_clean': 842.0, 'total': 1107.0}]\n"
     ]
    }
   ],
   "source": [
    "#Raw numbers example\n",
    "#Dictionary with modules as keys\n",
    "module_5 = data_raw['5']\n",
    "#Dictionary with ASIC's as keys\n",
    "module_5_asic_0 = data_raw['5']['0']\n",
    "#Dictionary with runs as keys\n",
    "module_5_asic_0_run_328555 = data_raw['5']['0']['328555']\n",
    "print(f\"There are {len(module_5_asic_0_run_328555)} subruns in this run: {module_5_asic_0_run_328555}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split_split': 0.0, 'split_clean': 251.0, 'clean_split': 4.0, 'clean_clean': 839.0, 'total': 1094.0}\n"
     ]
    }
   ],
   "source": [
    "#Array of subruns\n",
    "module_5_asic_0_run_328555_second_subrun = data_raw['5']['0']['328555'][1]\n",
    "print(module_5_asic_0_run_328555_second_subrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first four keys have two words in the key name. The first word is the classification according to the derivative algorithm. The second word is the classification according to the peak position algorithm. The last key is the total number of events used in the subrun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of events in this subrun that are very likely clean: 0.7669104204753199\n"
     ]
    }
   ],
   "source": [
    "super_clean_perc = module_5_asic_0_run_328555_second_subrun['clean_clean'] / module_5_asic_0_run_328555_second_subrun['total']\n",
    "print(f\"Fraction of events in this subrun that are very likely clean: {super_clean_perc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file titled 'split_dict_status.json' contains the split classification of runs for a given ASIC. It seems that an entire run of data for a given ASIC is either highly split or devoid of splits and therefore can be classified as split or clean. The file contains a multi-level dictionary with keys corresponding to module numbers, ASIC numbers, and run numbers. The value that corresponds to a run number key is a dictionary with three values. The keys for the lowest level dictionary are 'derivative', 'peak', and 'best', corresponding to the split status of the run according to the derivative algorithm, the peak position algorithm, and the best guess, respectively. Keep in mind that True corresponds to split and False corresponds to clean. The example below should make things more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'derivative': True, 'peak': False, 'best': False}\n"
     ]
    }
   ],
   "source": [
    "#Run status example\n",
    "#Dictionary with modules as keys\n",
    "module_5 = data_status['5']\n",
    "#Dictionary with ASIC's as keys\n",
    "module_5_asic_0 = data_status['5']['0']\n",
    "#Dictionary with runs as keys\n",
    "module_5_asic_0_run_328555 = data_status['5']['0']['328555']\n",
    "print(module_5_asic_0_run_328555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best guess is that this run is clean.\n"
     ]
    }
   ],
   "source": [
    "if data_status['5']['0']['328557']['best']:\n",
    "    print(f\"Best guess is that this run is split.\")\n",
    "else:\n",
    "    print(f\"Best guess is that this run is clean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of Runs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Crab runs: 328555, 328557, 328564, 328565, 328567, 328569, 328572, 328573, 328574, 328581, 328583,\n",
    "         328585, 328592, 328597, 328599, 328606, 328608, 328610, 328615, 328617, 328619, 328627,\n",
    "         328629, 328630, 328631, 328640, 328642, 328646, 328700, 328717, 328733, 328748, 328750,\n",
    "         328761, 328770, 328772, 328781, 328792, 328794, 328821, 328846, 328854, 328856, 328865,\n",
    "         328867 \n",
    "         \n",
    "List of Markarian runs: 331543, 331549, 331550, 331551, 331552, 331653, 331654, 331655, 331659, 331661,\n",
    "         331663, 331664, 331675, 331676, 331760, 331761, 331762, 331775, 331776, 331779, 331780, 331784,\n",
    "         331787, 331789, 331792, 331798, 331799, 331816, 331817, 331818, 331819, 331822, 331823, 331828,\n",
    "         331831, 331834, 331838, 331843, 331844, 331847, 331848, 331851, 331857, 331859, 331860, 331861,\n",
    "         331862, 331865, 331866, 331868, 331869, 331870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is useful for determining the module and ASIC number of a given pixel. Entering a pixel number returns the pixel number of all the pixels in the ASIC, the ASIC number, and the module number. The pixel number here starts at zero in the bottom left corner of the camera in sky view and increments by one moving left to right. The first row in sky view contains pixel numbers 0-39, the second 40-79, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_select(pix):\n",
    "    \"\"\"\n",
    "    Accepts a pixel index as an input and returns all the pixel in the same ASIC as well as the module and ASIC number.\n",
    "    The pixel index is determined by counting off pixels left to right, then bottom to top from the sky view of the\n",
    "    camera.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Determine the pixel, ASIC, and module row and column that the pixel resides in\n",
    "    pix_row = pix // 40\n",
    "    pix_col = pix % 40\n",
    "    asic_row = pix_row // 4\n",
    "    asic_col = pix_col // 4\n",
    "    mod_row = asic_row // 2\n",
    "    mod_col = asic_col // 2\n",
    "    \n",
    "    #Populate an array with the index of pixels in the same ASIC\n",
    "    result = []\n",
    "    count = asic_row * 160\n",
    "    count += asic_col * 4\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            result.append(count)\n",
    "            count += 1\n",
    "        count += 36\n",
    "    \n",
    "    #Find the ASIC number (recall that each module column is rotated 180 degrees)\n",
    "    if mod_col % 2 == 0:\n",
    "        asic_num = (3 - (2 * (asic_row % 2))) - (1 - (asic_col % 2))\n",
    "    else:\n",
    "        asic_num = (2 * (asic_row % 2)) + (1 - (asic_col % 2))\n",
    "        \n",
    "    #Module ordering in sky view\n",
    "    mod_location = [[6,107,114,111,100],\n",
    "    [7,112,124,123,115],\n",
    "    [8,121,110,108,119],\n",
    "    [9,106,126,125,103],\n",
    "    [2,3,1,5,4]]\n",
    "    \n",
    "    #Get the module number\n",
    "    mod_num = mod_location[mod_row][mod_col]\n",
    "    \n",
    "    return result, asic_num, mod_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to find the percentage of events across the camera for a run that are clean. Here is how we would determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 320, 324, 328, 332, 336, 340, 344, 348, 352, 356, 480, 484, 488, 492, 496, 500, 504, 508, 512, 516, 640, 644, 648, 652, 656, 660, 664, 668, 672, 676, 800, 804, 808, 812, 816, 820, 824, 828, 832, 836, 960, 964, 968, 972, 976, 980, 984, 988, 992, 996, 1120, 1124, 1128, 1132, 1136, 1140, 1144, 1148, 1152, 1156, 1280, 1284, 1288, 1292, 1296, 1300, 1304, 1308, 1312, 1316, 1440, 1444, 1448, 1452, 1456, 1460, 1464, 1468, 1472, 1476] [2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1] [6, 6, 107, 107, 114, 114, 111, 111, 100, 100, 6, 6, 107, 107, 114, 114, 111, 111, 100, 100, 7, 7, 112, 112, 124, 124, 123, 123, 115, 115, 7, 7, 112, 112, 124, 124, 123, 123, 115, 115, 8, 8, 121, 121, 110, 110, 108, 108, 119, 119, 8, 8, 121, 121, 110, 110, 108, 108, 119, 119, 9, 9, 106, 106, 126, 126, 125, 125, 103, 103, 9, 9, 106, 106, 126, 126, 125, 125, 103, 103, 2, 2, 3, 3, 1, 1, 5, 5, 4, 4, 2, 2, 3, 3, 1, 1, 5, 5, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "pixel_list = []\n",
    "asic_list = []\n",
    "mod_list = []\n",
    "#Loop through ASIC's\n",
    "for n in range(100):\n",
    "    #Choose a pixel in each each ASIC. Here we use the pixel in the bottom left corner.\n",
    "    #Increase pixel number by 160 every 10 loops (go up an ASIC row) and 4 every loop (go across an ASIC column)\n",
    "    pix = ((n // 10) * 160) + (4 * (n % 10))\n",
    "    pixel_list.append(pix)\n",
    "    \n",
    "    #Find the corresponding ASIC and Module number\n",
    "    r, a, m = loc_select(pix)\n",
    "    asic_list.append(a)\n",
    "    mod_list.append(m)\n",
    "print(pixel_list, asic_list, mod_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 110, ASIC 2 has no data for run 328555.\n",
      "Module 110, ASIC 3 has no data for run 328555.\n",
      "Module 110, ASIC 0 has no data for run 328555.\n",
      "Module 110, ASIC 1 has no data for run 328555.\n",
      "Run 328555 has 35.05105367139205% of events that are very likely clean\n"
     ]
    }
   ],
   "source": [
    "#Count the number of events that are considered clean by both algorithms\n",
    "clean_count = 0\n",
    "#Count the total number of events\n",
    "total_count = 0\n",
    "#The run we're interested in\n",
    "run = 328555\n",
    "#Loop through the ASIC's\n",
    "for n, mod in enumerate(mod_list):\n",
    "    #Check if we have data for that run and ASIC combination\n",
    "    try:\n",
    "        subruns = data_raw[str(mod)][str(asic_list[n])][str(run)]\n",
    "    except:\n",
    "        print(f\"Module {mod}, ASIC {asic_list[n]} has no data for run {run}.\")\n",
    "    #Loop through the subruns\n",
    "    for m, sub in enumerate(subruns):\n",
    "        clean_count += sub['clean_clean']\n",
    "        total_count += sub['total']\n",
    "\n",
    "#Print results\n",
    "print(f\"Run {run} has {100 * clean_count / total_count}% of events that are very likely clean\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 110 is the empty module and will always contain None.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Module 110 is the empty module and will always contain {data_raw['110']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
